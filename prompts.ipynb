{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b79cbfe5-d3ad-4a2f-a554-cbed6319608b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: python-dotenv in /Users/berkergoz/Library/Python/3.9/lib/python/site-packages (1.0.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: huggingface_hub in /Users/berkergoz/Library/Python/3.9/lib/python/site-packages (0.28.1)\n",
      "Requirement already satisfied: filelock in /Users/berkergoz/Library/Python/3.9/lib/python/site-packages (from huggingface_hub) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/berkergoz/Library/Python/3.9/lib/python/site-packages (from huggingface_hub) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/berkergoz/Library/Python/3.9/lib/python/site-packages (from huggingface_hub) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/berkergoz/Library/Python/3.9/lib/python/site-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in /Users/berkergoz/Library/Python/3.9/lib/python/site-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/berkergoz/Library/Python/3.9/lib/python/site-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/berkergoz/Library/Python/3.9/lib/python/site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/berkergoz/Library/Python/3.9/lib/python/site-packages (from requests->huggingface_hub) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/berkergoz/Library/Python/3.9/lib/python/site-packages (from requests->huggingface_hub) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/berkergoz/Library/Python/3.9/lib/python/site-packages (from requests->huggingface_hub) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/berkergoz/Library/Python/3.9/lib/python/site-packages (from requests->huggingface_hub) (2022.12.7)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# install libraries, skip if you have libraries downloaded already\n",
    "! pip install python-dotenv\n",
    "! pip install huggingface_hub "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6a74555-0ea4-4271-8405-453fa9dd449d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "from huggingface_hub import InferenceClient\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3212c168-857c-4506-9aa8-f43bb6da55ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load .env get get the API KEY\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"HF_TOKEN\")\n",
    "# os.environ[\"HF_TOKEN\"]=\"hf_xxxxxxxxxxx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f64e591b-d4e0-4e11-9bea-3fc86cec0aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to Llama client, there are 2 alternatives\n",
    "#client = InferenceClient(\"meta-llama/Llama-3.2-3B-Instruct\")\n",
    "client = InferenceClient(\"https://jc26mwg228mkj8dw.us-east-1.aws.endpoints.huggingface.cloud\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d3e1f521-e25e-4ee3-84b2-9e30f02e0723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Berlin\n",
      "What is the capital of France:  Paris\n",
      "What is the capital of Italy:  Rome\n",
      "What is the capital of Spain:  Madrid\n",
      "What is the capital of Portugal:  Lisbon\n",
      "What is the capital of Sweden:  Stockholm\n",
      "What is the capital of Denmark:  Copenhagen\n",
      "What is the capital of Norway:  Oslo\n",
      "What is the capital of Finland:  Helsinki\n",
      "What is the capital of Greece:  Athens\n",
      "What is the capital of Turkey: \n"
     ]
    }
   ],
   "source": [
    "output = client.text_generation(\"what is the capital of Germany: \", max_new_tokens = 100)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd2c1a3-8451-40f4-85e3-0e4468438aec",
   "metadata": {},
   "source": [
    "Text Generation is continued until EOS Token is generated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71fadb5-d241-403f-aeb6-aeb9c44f5677",
   "metadata": {},
   "source": [
    "## Not Recommended: Using special token get the result directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "bd3490fc-97fb-456f-a160-6be7369a797e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n"
     ]
    }
   ],
   "source": [
    "prompt=\"\"\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
    "The capital of Germany is<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\"\n",
    "output = client.text_generation(prompt, max_new_tokens = 100)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454789de-bd40-4709-914e-598d38f4c8e5",
   "metadata": {},
   "source": [
    "## Recommended Approach: Using Chat Method, Applying Chat Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6308b9f8-5d78-4095-9575-39ce2ab64a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Berlin.\n"
     ]
    }
   ],
   "source": [
    "output = client.chat.completions.create(\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": \"The capital of Germany is\"},\n",
    "        ], \n",
    "        stream = False,\n",
    "        max_tokens = 100,\n",
    "        )\n",
    "        \n",
    "print(output.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57564d38-7459-4614-b122-2d6840e71f8b",
   "metadata": {},
   "source": [
    "# Example: \n",
    "## Creating an agent that uses dummy function that tells the humidity of a location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "00ff070a-4b2a-4c7b-8019-75c33af150b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "dummy_humidty: Get the current humidty in a given location\n",
    "\n",
    "The way you use the tools is by specifying a json blob.\n",
    "Specifically, this json should have a `action` key (with the name of the tool to use) and a `action_input` key (with the input to the tool going here).\n",
    "\n",
    "The only values that should be in the \"action\" field are:\n",
    "dummy_humidity: Get the current humidity in a given location, args: {\"location\": {\"type\": \"string\"}}\n",
    "example use :\n",
    "```\n",
    "{{\n",
    "  \"action\": \"dummy_humidity\",\n",
    "  \"action_input\": {\"location\": \"Dortmund\"}\n",
    "}}\n",
    "\n",
    "ALWAYS use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about one action to take. Only one action at a time in this format:\n",
    "\n",
    "Action:\n",
    "```\n",
    "$JSON_BLOB\n",
    "```\n",
    "Observation: the result of the action. This Observation is unique, complete, and the source of truth.\n",
    "... (this Thought/Action/Observation can repeat N times, you should take several steps when needed. The $JSON_BLOB must be formatted as markdown and only use a SINGLE action at a time.)\n",
    "\n",
    "\n",
    "You must always end your output with the following format:\n",
    "\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Now begin! Reminder to ALWAYS use the exact characters `Final Answer:` when you provide a definitive answer. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2e71a933-515c-4bde-8c3e-49e721709445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "dummy_humidty: Get the current humidty in a given location\n",
      "\n",
      "The way you use the tools is by specifying a json blob.\n",
      "Specifically, this json should have a `action` key (with the name of the tool to use) and a `action_input` key (with the input to the tool going here).\n",
      "\n",
      "The only values that should be in the \"action\" field are:\n",
      "dummy_humidity: Get the current humidity in a given location, args: {\"location\": {\"type\": \"string\"}}\n",
      "example use :\n",
      "```\n",
      "{{\n",
      "  \"action\": \"dummy_humidity\",\n",
      "  \"action_input\": {\"location\": \"Dortmund\"}\n",
      "}}\n",
      "\n",
      "ALWAYS use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about one action to take. Only one action at a time in this format:\n",
      "\n",
      "Action:\n",
      "```\n",
      "$JSON_BLOB\n",
      "```\n",
      "Observation: the result of the action. This Observation is unique, complete, and the source of truth.\n",
      "... (this Thought/Action/Observation can repeat N times, you should take several steps when needed. The $JSON_BLOB must be formatted as markdown and only use a SINGLE action at a time.)\n",
      "\n",
      "\n",
      "You must always end your output with the following format:\n",
      "\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Now begin! Reminder to ALWAYS use the exact characters `Final Answer:` when you provide a definitive answer. \n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "What's the humidity in Dortmund ?\n",
      "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use special tokens \n",
    "prompt=f\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "{SYSTEM_PROMPT}\n",
    "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "What's the humidity in Dortmund ?\n",
    "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "11931bd8-9300-4d01-91a6-dbac34272125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action:\n",
      "```\n",
      "{{\n",
      "  \"action\": \"dummy_humidity\",\n",
      "  \"action_input\": {\"location\": \"Dortmund\"}\n",
      "}}\n",
      "```\n",
      "Observation: The current humidity in Dortmund is not available in the provided tool.\n"
     ]
    }
   ],
   "source": [
    "# halluciniated output: It will generate observation w/o using the tool\n",
    "output = client.text_generation(\n",
    "    prompt,\n",
    "    max_new_tokens = 500)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e5051541-ca58-450e-8c3c-4e5d0172f518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action:\n",
      "```\n",
      "{{\n",
      "  \"action\": \"dummy_humidity\",\n",
      "  \"action_input\": {\"location\": \"Dortmund\"}\n",
      "}}\n",
      "```\n",
      "Observation:\n"
     ]
    }
   ],
   "source": [
    "# avoid halucination, stop it at Observation\n",
    "output = client.text_generation(\n",
    "    prompt,\n",
    "    max_new_tokens=500,\n",
    "    stop=[\"Observation:\"] \n",
    ")\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "661e3814-4ded-4cd1-9580-0ee4b63e7e5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dortmund has a humidity of 80%. \\n'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dummy_humidity(location):\n",
    "    return f\"{location} has a humidity of 80%. \\n\"\n",
    "\n",
    "dummy_humidity(\"Dortmund\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e516709b-42e7-4a5e-bead-deaa3c361560",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "dummy_humidty: Get the current humidty in a given location\n",
      "\n",
      "The way you use the tools is by specifying a json blob.\n",
      "Specifically, this json should have a `action` key (with the name of the tool to use) and a `action_input` key (with the input to the tool going here).\n",
      "\n",
      "The only values that should be in the \"action\" field are:\n",
      "dummy_humidity: Get the current humidity in a given location, args: {\"location\": {\"type\": \"string\"}}\n",
      "example use :\n",
      "```\n",
      "{{\n",
      "  \"action\": \"dummy_humidity\",\n",
      "  \"action_input\": {\"location\": \"Dortmund\"}\n",
      "}}\n",
      "\n",
      "ALWAYS use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about one action to take. Only one action at a time in this format:\n",
      "\n",
      "Action:\n",
      "```\n",
      "$JSON_BLOB\n",
      "```\n",
      "Observation: the result of the action. This Observation is unique, complete, and the source of truth.\n",
      "... (this Thought/Action/Observation can repeat N times, you should take several steps when needed. The $JSON_BLOB must be formatted as markdown and only use a SINGLE action at a time.)\n",
      "\n",
      "\n",
      "You must always end your output with the following format:\n",
      "\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Now begin! Reminder to ALWAYS use the exact characters `Final Answer:` when you provide a definitive answer. \n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "What's the humidity in Dortmund ?\n",
      "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "Action:\n",
      "```\n",
      "{{\n",
      "  \"action\": \"dummy_humidity\",\n",
      "  \"action_input\": {\"location\": \"Dortmund\"}\n",
      "}}\n",
      "```\n",
      "Observation:Dortmund has a humidity of 80%. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# combine prompt with the cutoff output and the result of the function\n",
    "new_prompt=prompt+output+dummy_humidity(\"Dortmund\")\n",
    "print(new_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b778dcd-6f68-419b-abaf-adab9f1226a4",
   "metadata": {},
   "source": [
    "The above prompt:\n",
    "1. Uses Special tokens of LLama to control the output\n",
    "2. Tells the agent what to do\n",
    "3. Describes the tool it needs to use\n",
    "4. EVentually the thinking process is described\n",
    "5. Thoght it how the act\n",
    "6. Observe it by interacting w. its environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "3a71de3f-90d9-4556-a090-a762fd5fc2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: I now know the final answer\n"
     ]
    }
   ],
   "source": [
    "# see the final output\n",
    "final_output = client.text_generation(new_prompt, max_new_tokens = 500)\n",
    "print(final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91edcc0-bd37-4c22-8f55-95e8aab1c2e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bdcd82-0e1e-4d5d-8058-aa33c1be565f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
